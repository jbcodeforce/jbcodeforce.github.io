# My machine learning summary and concepts

src:

* python machine learning - Sebastian Raschka
* Ng machine learning - coursera training

Raschka, Sebastian. Python Machine Learning . Packt Publishing. Kindle Edition. 

## Main concepts

IBM Research definition: "AI is anything that makes machines act more intelligently". It is Augmented Intelligence. The goal is to put the information that subject matter experts need at their fingertips, and back that information up with evidence, so that the experts can make more informed decisions.

Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. ML tries to find a function that predicts y from a matrix of values X, and continuously measures the prediction performance.

The problem at hand is a 'classification' problem when the learned attribute is categorical or nominal (y is 0 or 1). The other type is called 'regression' and the learned attribute is continuous numerical value.

Different types machine learning algorithms:

- Supervised learning
- Unsupervised learning
- Reinforcement learning
- Deep learning

### Supervised learning:

The main goal in supervised learning is to learn a model from labeled training data that allows us to make predictions about unseen or future data. **Supervised** because we give to the algorithm a dataset with a right answers (y). There are different categories of supervised learning:

* **Classification** problem is when we are trying to predict one of a few discrete-valued outputs, such as whether it is Sunny (which we might designate as class 0), Cloudy (say class 1) or Rainy (class 2).
The class labels are defined as multiple classes or binary classification task, where the machine learning algorithm learns a set of rules in order to distinguish between the possible classes.

Here is an example of data and classes from the NIST's `iris flower` dataset: 4 features (*a feature is an attribute to use for classifying*), three potential classes:

```python
feature_names= ['sepal length (cm)', 'sepal width (cm)', 
'petal length (cm)', 'petal width (cm)']
target_names= ['setosa', 'versicolor', 'virginica']
data = [[ 5.1,  3.5,  1.4,  0.2],[ 4.9,  3. ,  1.4,  0.2]]

labels = [0, 0, 0, 0,…1,1,1,… 2,2,2]
```
First row of data correspond to first label of value 0.

* **Regression**, where the outcome signal is a continuous value. In the table below the Price is the outcome (y) the size # of bedrooms, age of the house,… are feature:

![](assets/docs/ml/images/house-table.png)

In regression analysis, we are given a number of predictor (explanatory) variables and a continuous response variable (outcome), and we try to find a relationship between those variables that allows us to predict an outcome.

---

### Unsupervised learning

With unsypervised learning, we are able to explore the structure of our data to extract meaningful information without the guidance of a known outcome variable or reward function. Giving a dataset we try to find tendency in the data, by using techniques like **clustering**: group data in clusters without having any prior knowledge of their group memberships. Example of unsupervised learning problems are: news.google.com, individuals genes map, organize large computer clusters, social network analysis, market segmentation, astronomical data analysis...

### Reinforcement learning

The goal is to develop a system (agent) that improves its performance based on interactions with the environment: it learns a series of actions that maximizes a reward via an exploratory trial-and-error approach or deliberative planning.  Can be used to play chess, or navigate around obstacles.


### Deep learning

When working on unstructured data like images, voice record, movies, text, the method is based on artificial neural networks.  It is very loosely based on how we think the human brain works. First, a collection of software “neurons” are created and connected together, allowing them to send messages to each other. Next, the network is asked to solve a problem, which it attempts to do over and over, each time strengthening the connections (weights on graph arc) that lead to success and diminishing those that lead to failure. 

#### References
* introduction to neural networks, Michael Nielsen’s Neural Networks and Deep Learning. 
* For a more technical overview, try Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
* https://www.safaribooksonline.com/library/view/deep-learning-with/9780134770826 John Krohn
* Excellent NN demo at http://playground.tensorflow.org/
* [Wikipedia](https://en.wikipedia.org/wiki/Deep_learning)

---

### Building machine learning system

It includes 4 components as outlined in figure below:

<img src="assets/docs/ml/images/building-method.png" width=900></img>

Raw data rarely comes in the form and shape that is necessary for the optimal performance of a learning algorithm. Thus, the preprocessing of the data is one of the most crucial steps in any machine learning application. Many machine learning algorithms also require that the selected features are on the **same scale** for optimal performance, which is often achieved by transforming the features in the range [0, 1] or a **standard normal distribution** with zero mean and the unit variance.  

Some selected features may be highly correlated and therefore redundant to a certain degree. In those cases, **dimensionality reduction** techniques are useful for compressing the features onto a lower dimensional subspace.  

Reducing the dimensionality of the feature space has the advantage that less storage space is required, and the learning algorithm can run much faster.   

To determine whether a machine learning algorithm not only performs well on the training set but also generalizes well to new data, we need to **randomly divide** the dataset into a separate **training** and **test set**.   

In practice, it is essential to compare at least a handful of different algorithms in order to train and select the best performing model.  

First we have to **decide** upon a **metric** to **measure performance**. One commonly used metric is **classification accuracy**, which is defined as the proportion of correctly classified instances. 

After selecting a model that has been fitted on the training dataset, we can use the test dataset to estimate how well it performs on this unseen data to estimate the generalization error.  

### Unsupervised dimensionality reduction

It is a commonly used approach in feature preprocessing to remove noise from data, which can also degrade the predictive performance of certain algorithms, and compress the data onto a smaller dimensional subspace while retaining most of the relevant information.

### Overfitting concept

Overfitting occurs when the train data creates a classifier that is very efficient on the train but not efficient on the test data. Low error rate on training data, high error rate on test data.

Once the model is evaluated on the training set and on the test set, the difference between the fit measures the model ability to generalize:

* Underfitting = high bias, low variance
* Overfitting = low bias, high variance.

<img src="assets/docs/ml/images/fit-patterns.png" width=300></img>
